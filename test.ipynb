{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain pinecone-client pypdf openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip show langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader # type: ignore\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # type: ignore\n",
    "from langchain.embeddings import OpenAIEmbeddings # type: ignore\n",
    "from langchain.llms import OpenAI # type: ignore\n",
    "from langchain.vectorstores import Pinecone# type: ignore\n",
    "from langchain.chains import RetrievalQA# type: ignore\n",
    "from langchain.prompts import PromptTemplate# type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Chunks Doucment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFDirectoryLoader(\"pdfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"You have {len(data)} documents\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 480, chunk_overlap=20, \n",
    "                                               separators=[\"\\n\\n\", \"\\n\", \" \",\".\",\",\",\"\"] ) \n",
    "\n",
    "# default separator list of [\"\\n\\n\", \"\\n\", \" \", \"\"] \n",
    "#can cause words to be split between chunks\n",
    "\n",
    "    #separators=[\n",
    "    #     \"\\n\\n\",\n",
    "    #     \"\\n\",\n",
    "    #     \" \",\n",
    "    #     \".\",\n",
    "    #     \",\",\n",
    "    #     \"\\u200B\",  # Zero-width space\n",
    "    #     \"\\uff0c\",  # Fullwidth comma\n",
    "    #     \"\\u3001\",  # Ideographic comma\n",
    "    #     \"\\uff0e\",  # Fullwidth full stop\n",
    "    #     \"\\u3002\",  # Ideographic full stop\n",
    "    #     \"\",\n",
    "    # ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"You have {len(text_chunks)} chunks\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import AzureOpenAIEmbeddings  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPENAI_API_KEY = \"sk-....\"\n",
    "#os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "#embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_embeddings = AzureOpenAIEmbeddings(\n",
    "    deployment=\"embeddings\",\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    openai_api_base=os.environ[\"OPENAI_API_BASE\"],\n",
    "    openai_api_type=\"azure\",\n",
    ")\n",
    "embedding = azure_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testEmbed = embedding.embed_query(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testEmbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"You have {len(testEmbed)} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')\n",
    "PINECONE_ENV = os.environ.get('PINECONE_ENV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = pinecone.Pinecone(api_key=PINECONE_API_KEY) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.Pinecone(api_key = PINECONE_API_KEY, environment = PINECONE_ENV)\n",
    "index_name = \"salesvector\"\n",
    "host = \"https://salesvector-zenjj4f.svc.gcp-starter.pinecone.io\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pinecone.Index(index_name, host)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Embeddings for each Text Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docsearch = pinecone.Pinecone.from_texts([t.page_content for t in text_chunks], embedding, index_name= index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in zip(range(len(text_chunks)), text_chunks):\n",
    "   query_result = embedding.embed_query(t.page_content)\n",
    "   index.upsert(\n",
    "   vectors=[\n",
    "        {\n",
    "            \"id\": str(i),  # Convert i to a string\n",
    "            \"values\": query_result, \n",
    "            \"metadata\": {\"text\":str(text_chunks[i].page_content)} # meta data as dic\n",
    "        }\n",
    "    ],\n",
    "    namespace=\"real\" \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- range(len(text_chunks)): Generates a sequence of numbers from 0 to the length of the text_chunks list minus 1. This sequence represents the indices of elements in the text_chunks list.\n",
    "\n",
    "- zip(range(len(text_chunks)), text_chunks): Combines the generated sequence of indices with the elements of the text_chunks list. This creates pairs where the first element of each pair is the index and the second element is the corresponding element from the text_chunks list.\n",
    "\n",
    "- for i, t in ...: Iterates over each pair generated by zip. In each iteration:\n",
    "\n",
    "- i represents the index of the current element in the text_chunks list.\n",
    "- t represents the corresponding element from the text_chunks list.\n",
    "\n",
    "\n",
    "**Allows you to iterate over each element in the text_chunks list along with its index, enabling you to perform operations or access elements based on both the index and the element itself.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"National sales meetings\"\n",
    "\"Signs that justify territory revision\"\n",
    "\"SMBO process\"\n",
    "query = \"SMBO process\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryEmbed = embedding.embed_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryEmbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = index.query(vector=queryEmbed, top_k=6, namespace='real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "for element in docs[\"matches\"]:\n",
    "    pprint(text_chunks[int(element[\"id\"])].page_content , width = 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consideraions:\n",
    "- Type of data\n",
    "- Search frequency : *Frequency of updates vs Frequency of Searches*\n",
    "- Chunk size : *Degree of detail vs summary*\n",
    "- Embedding Model - Dimensions: *GTE-Base (Graft Default), GTE-Large,\n",
    ",GTE-Small ,E5-Small, E5-Base*\n",
    "- Tokens and Costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercises:\n",
    "Experiment with:\n",
    "- chunk sizes\n",
    "- Separators\n",
    "- OpenSource Embedding Models: \n",
    "- Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
